
\documentclass[a4paper,conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm2e}
\usepackage{subfigure}
\usepackage{threeparttable}
\usepackage{color}

\newcommand{\note}[1]{\textbf{\color{blue}#1}}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{CNN for Image Sentiment Analysis\\ with Triplet Loss}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Zheng Lu, Yunhe Feng}
\IEEEauthorblockA{
Department of Electrical Engineering and Computer Science\\
University of Tennessee, Knoxville\\
Email: \{zlu12, yfeng14\}@vols.utk.edu}
}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
Understanding the underlying attitude of people towards a given image automatically is important for many applications. The rapid growth of social media provides new opportunities and challenges to design image sentiment inference systems. Due to the weak relation between low-level visual features and sentiment, recent work focus on constructing mid-level semantic representation that can both be easily detected from the input images and be mapped to the sentiment class. However, although current convolutional neural networks are good at identifying objects, it is not as effective when applied for mid-level semantic representations with adjective parts. To overcome this challenge, we adopt a variant of convolutional neural networks with triplet loss to perform end-to-end learning that can automatically generate the most suitable mid-level features. We show the effectiveness of our approaches by detecting both mid-level representations and predicting sentiment of various image datasets and show significant improvement against the baseline approaches.
\end{abstract}

\IEEEpeerreviewmaketitle

\input{introduction}
\input{relatedwork}
\input{design}
\input{evaluation}
\input{conclusion}

% use section* for acknowledgment
%\section*{Acknowledgment}


%The authors would like to thank...

\clearpage

\bibliographystyle{abbrv}
\bibliography{reference}


% that's all folks
\end{document}


